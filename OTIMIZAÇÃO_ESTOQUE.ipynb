{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPAsks4tifpfoJSvNrBSjD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DAUZEX/Otimiza-o-de-Estoque/blob/main/OTIMIZA%C3%87%C3%83O_ESTOQUE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfBPGJviAakR",
        "outputId": "a00152b0-1359-45e1-9d07-9eb7e6bae321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:n_changepoints greater than number of observations. Using 13.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpu5ah332x/tqhghodj.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpu5ah332x/b2ab94y3.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.11/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=61330', 'data', 'file=/tmp/tmpu5ah332x/tqhghodj.json', 'init=/tmp/tmpu5ah332x/b2ab94y3.json', 'output', 'file=/tmp/tmpu5ah332x/prophet_modelchz8ay7b/prophet_model-20250610224214.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "22:42:14 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:42:14 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 9.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpu5ah332x/i6jovfqq.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpu5ah332x/3spfilhv.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.11/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=29443', 'data', 'file=/tmp/tmpu5ah332x/i6jovfqq.json', 'init=/tmp/tmpu5ah332x/3spfilhv.json', 'output', 'file=/tmp/tmpu5ah332x/prophet_modelhnh8fkku/prophet_model-20250610224215.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "22:42:15 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:42:23 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 7.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpu5ah332x/pla0kqqe.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmpu5ah332x/0430hj3y.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.11/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=57472', 'data', 'file=/tmp/tmpu5ah332x/pla0kqqe.json', 'init=/tmp/tmpu5ah332x/0430hj3y.json', 'output', 'file=/tmp/tmpu5ah332x/prophet_modelf1qv8c6h/prophet_model-20250610224224.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "22:42:24 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "22:42:25 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 2.\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 2.\n",
            "INFO:prophet:n_changepoints greater than number of observations. Using 2.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resumo das Previsões e Pedidos para 2025:\n",
            "\n",
            "Produto: D4DS-K3\n",
            "    Data_Pedido Data_Demanda  Quantidade_Pedido\n",
            "139  2024-12-05   2025-01-04                  3\n",
            "140  2024-12-06   2025-01-05                 12\n",
            "141  2024-12-07   2025-01-06                 19\n",
            "142  2024-12-08   2025-01-07                 25\n",
            "143  2024-12-09   2025-01-08                 29\n",
            "\n",
            "Produto: CP1E-N40DT1-D\n",
            "   Data_Pedido Data_Demanda  Quantidade_Pedido\n",
            "26  2024-09-03   2025-01-01                  3\n",
            "27  2024-09-04   2025-01-02                  3\n",
            "28  2024-09-05   2025-01-03                  3\n",
            "29  2024-09-06   2025-01-04                  3\n",
            "30  2024-09-07   2025-01-05                  3\n",
            "\n",
            "Produto: E3Z-R61\n",
            "   Data_Pedido Data_Demanda  Quantidade_Pedido\n",
            "65  2024-10-03   2025-01-01                  4\n",
            "66  2024-10-04   2025-01-02                  4\n",
            "67  2024-10-05   2025-01-03                  5\n",
            "68  2024-10-06   2025-01-04                  5\n",
            "69  2024-10-07   2025-01-05                  6\n",
            "\n",
            "Produto: Z-15GW4-B\n",
            "   Data_Pedido Data_Demanda  Quantidade_Pedido\n",
            "37  2024-10-03   2025-01-01                  7\n",
            "38  2024-10-04   2025-01-02                  7\n",
            "39  2024-10-05   2025-01-03                  8\n",
            "40  2024-10-06   2025-01-04                  9\n",
            "41  2024-10-07   2025-01-05                  9\n",
            "\n",
            "Produto: S8VK-G03024\n",
            "   Data_Pedido Data_Demanda  Quantidade_Pedido\n",
            "21  2024-10-03   2025-01-01                  5\n",
            "22  2024-10-04   2025-01-02                  5\n",
            "23  2024-10-05   2025-01-03                  5\n",
            "24  2024-10-06   2025-01-04                  5\n",
            "25  2024-10-07   2025-01-05                  5\n",
            "\n",
            "Produto: NB3Q-TW01B\n",
            "   Data_Pedido Data_Demanda  Quantidade_Pedido\n",
            "8   2024-10-03   2025-01-01                  0\n",
            "9   2024-10-04   2025-01-02                  0\n",
            "10  2024-10-05   2025-01-03                  0\n",
            "11  2024-10-06   2025-01-04                  0\n",
            "12  2024-10-07   2025-01-05                  0\n",
            "\n",
            "Arquivo '/content/pedidos_2025_avancado.csv' gerado com sucesso.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from prophet import Prophet\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.cluster import KMeans\n",
        "from datetime import timedelta\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Dados da planilha\n",
        "data = {\n",
        "    'EMPRESA': ['FACENS']*27,\n",
        "    'PRODUTO': ['E3Z-R61', 'E3Z-R61', 'E3Z-R61', 'E3Z-R61', 'E3Z-R61', 'E3Z-R61', 'E3Z-R61', 'E3Z-R61', 'E3Z-R61',\n",
        "                'Z-15GW4-B', 'Z-15GW4-B', 'Z-15GW4-B', 'Z-15GW4-B', 'Z-15GW4-B', 'Z-15GW4-B', 'Z-15GW4-B',\n",
        "                'D4DS-K3', 'D4DS-K3', 'D4DS-K3', 'D4DS-K3', 'D4DS-K3',\n",
        "                'S8VK-G03024', 'S8VK-G03024',\n",
        "                'CP1E-N40DT1-D', 'CP1E-N40DT1-D',\n",
        "                'NB3Q-TW01B', 'NB3Q-TW01B'],\n",
        "    'MARCA': ['OMRON']*27,\n",
        "    'QTD': [3, 2, 8, 1, 1, 1, 5, 1, 8, 2, 3, 5, 4, 2, 1, 6, 4, 2, 4, 5, 7, 5, 5, 3, 3, 2, 2],\n",
        "    'DATA CONSUMO 2023': ['9/21/23', '7/6/23', '12/2/23', '8/2/23', '3/28/23', '1/4/23', '1/11/23', '8/26/23', '1/3/23',\n",
        "                         '1/1/23', '12/21/23', '3/17/23', '10/29/23', '4/9/23', '8/22/23', '7/16/23',\n",
        "                         '10/30/23', '3/20/23', '10/25/23', '3/15/23', '4/20/23',\n",
        "                         '12/7/23', '6/18/23',\n",
        "                         '12/11/23', '6/1/23',\n",
        "                         '12/4/23', '6/15/23'],\n",
        "    'DATA CONSUMO 2024': ['11/14/24', '9/29/24', '8/2/24', '2/15/24', '1/2/24', '1/18/24', '3/7/24', '7/25/24', '7/2/24',\n",
        "                          '6/20/24', '8/21/24', '9/20/24', '2/1/24', '2/2/24', '2/2/24', '12/7/24',\n",
        "                          '8/27/24', '1/5/24', '8/19/24', '7/26/24', '3/21/24',\n",
        "                          '12/14/24', '6/22/24',\n",
        "                          '12/9/24', '6/30/24',\n",
        "                          '12/27/24', '6/18/24'],\n",
        "    'LEAD TIME DO PRODUTO': ['90 DIAS']*9 + ['75 DIAS']*7 + ['30 DIAS']*5 + ['60 DIAS']*2 + ['120 DIAS']*2 + ['30 DIAS']*2\n",
        "}\n",
        "\n",
        "# Verificar se os dados foram carregados corretamente\n",
        "if not data:\n",
        "    raise ValueError(\"Erro: Dados de entrada não foram fornecidos.\")\n",
        "\n",
        "# Criar DataFrame\n",
        "try:\n",
        "    df = pd.DataFrame(data)\n",
        "except Exception as e:\n",
        "    raise ValueError(f\"Erro ao criar DataFrame: {e}\")\n",
        "\n",
        "# Função para parsear datas com robustez\n",
        "def parse_date(date_str):\n",
        "    try:\n",
        "        return pd.to_datetime(date_str, format='%m/%d/%y', errors='coerce')\n",
        "    except:\n",
        "        return pd.to_datetime(date_str, errors='coerce')\n",
        "\n",
        "# Converter colunas de datas\n",
        "df['DATA CONSUMO 2023'] = df['DATA CONSUMO 2023'].apply(parse_date)\n",
        "df['DATA CONSUMO 2024'] = df['DATA CONSUMO 2024'].apply(parse_date)\n",
        "\n",
        "# Verificar se há datas inválidas\n",
        "if df[['DATA CONSUMO 2023', 'DATA CONSUMO 2024']].isnull().any().any():\n",
        "    print(\"Aviso: Algumas datas não puderam ser convertidas e foram marcadas como NaN.\")\n",
        "\n",
        "# Combinar dados de 2023 e 2024\n",
        "df_2023 = df[['PRODUTO', 'QTD', 'DATA CONSUMO 2023']].rename(columns={'DATA CONSUMO 2023': 'DATA', 'QTD': 'QUANTIDADE'})\n",
        "df_2024 = df[['PRODUTO', 'QTD', 'DATA CONSUMO 2024']].rename(columns={'DATA CONSUMO 2024': 'DATA', 'QTD': 'QUANTIDADE'})\n",
        "df_2023 = df_2023.dropna(subset=['DATA'])\n",
        "df_2024 = df_2024.dropna(subset=['DATA'])\n",
        "df_combined = pd.concat([df_2023, df_2024])\n",
        "\n",
        "# Extrair lead times\n",
        "lead_times = df[['PRODUTO', 'LEAD TIME DO PRODUTO']].drop_duplicates().set_index('PRODUTO')\n",
        "lead_times['LEAD TIME DO PRODUTO'] = lead_times['LEAD TIME DO PRODUTO'].str.extract('(\\d+)').astype(int)\n",
        "\n",
        "# Função para prever demanda\n",
        "def prever_demanda_hibrida(produto, dados):\n",
        "    df_produto = dados[dados['PRODUTO'] == produto][['DATA', 'QUANTIDADE']].rename(columns={'DATA': 'ds', 'QUANTIDADE': 'y'})\n",
        "    df_produto = df_produto.groupby('ds').sum().reset_index()\n",
        "    if len(df_produto) < 2:\n",
        "        print(f\"Aviso: Produto {produto} tem poucos dados para previsão.\")\n",
        "        return pd.DataFrame(columns=['ds', 'yhat'])\n",
        "\n",
        "    # Prophet\n",
        "    prophet_model = Prophet(yearly_seasonality=True, daily_seasonality=False, weekly_seasonality=False)\n",
        "    prophet_model.fit(df_produto)\n",
        "    future = prophet_model.make_future_dataframe(periods=365, freq='D')\n",
        "    prophet_forecast = prophet_model.predict(future)[['ds', 'yhat']]\n",
        "\n",
        "    # XGBoost\n",
        "    df_produto['month'] = df_produto['ds'].dt.month\n",
        "    df_produto['quarter'] = df_produto['ds'].dt.quarter\n",
        "    X = df_produto[['month', 'quarter']]\n",
        "    y = df_produto['y']\n",
        "    xgb_model = XGBRegressor()\n",
        "    xgb_model.fit(X, y)\n",
        "    future_features = pd.DataFrame({\n",
        "        'month': future['ds'].dt.month,\n",
        "        'quarter': future['ds'].dt.quarter\n",
        "    })\n",
        "    xgb_forecast = xgb_model.predict(future_features)\n",
        "\n",
        "    # Ensemble\n",
        "    ensemble_forecast = 0.7 * prophet_forecast['yhat'] + 0.3 * xgb_forecast\n",
        "    forecast_2025 = pd.DataFrame({\n",
        "        'ds': future['ds'],\n",
        "        'yhat': ensemble_forecast.clip(0).round()\n",
        "    })\n",
        "    return forecast_2025[forecast_2025['ds'].dt.year == 2025][forecast_2025['yhat'] > 0]\n",
        "\n",
        "# Função para otimizar pedidos\n",
        "def otimizar_pedidos(produto, forecast, lead_time, custo_pedido=100, custo_armazenamento=5, penalidade_ruptura=50):\n",
        "    if forecast.empty:\n",
        "        return pd.DataFrame(columns=['Produto', 'Data_Pedido', 'Data_Demanda', 'Quantidade_Pedido'])\n",
        "\n",
        "    demandas = forecast['yhat'].values\n",
        "    horizonte = len(demandas)\n",
        "    dp = np.zeros(horizonte + 1)\n",
        "    pedidos = [0] * horizonte\n",
        "\n",
        "    for t in range(horizonte):\n",
        "        min_custo = float('inf')\n",
        "        for q in range(int(max(demandas[t:])) + 1):\n",
        "            estoque = q - demandas[t]\n",
        "            custo = custo_pedido * (q > 0) + custo_armazenamento * max(0, estoque)\n",
        "            if estoque < 0:\n",
        "                custo += penalidade_ruptura * abs(estoque)\n",
        "            if t + int(lead_time) < horizonte:\n",
        "                custo += dp[t + int(lead_time)]\n",
        "            if custo < min_custo:\n",
        "                min_custo = custo\n",
        "                pedidos[t] = q\n",
        "        dp[t + 1] = min_custo\n",
        "\n",
        "    return pd.DataFrame({\n",
        "        'Produto': [produto] * len(forecast),\n",
        "        'Data_Pedido': forecast['ds'] - timedelta(days=int(lead_time)),\n",
        "        'Data_Demanda': forecast['ds'],\n",
        "        'Quantidade_Pedido': pedidos[:len(forecast)]\n",
        "    })\n",
        "\n",
        "# Função para agrupar pedidos\n",
        "def agrupar_pedidos(produtos, lead_times, forecast_dict):\n",
        "    features = pd.DataFrame({\n",
        "        'lead_time': [lead_times.loc[p, 'LEAD TIME DO PRODUTO'] for p in produtos],\n",
        "        'demanda_media': [forecast_dict[p]['yhat'].mean() if not forecast_dict[p].empty else 0 for p in produtos]\n",
        "    })\n",
        "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "    clusters = kmeans.fit_predict(features)\n",
        "\n",
        "    pedidos_agrupados = []\n",
        "    for cluster in range(3):\n",
        "        cluster_produtos = [produtos[i] for i in range(len(produtos)) if clusters[i] == cluster]\n",
        "        if cluster_produtos:\n",
        "            lead_time_max = max(lead_times.loc[cluster_produtos, 'LEAD TIME DO PRODUTO'])\n",
        "            for p in cluster_produtos:\n",
        "                forecast = forecast_dict[p]\n",
        "                if not forecast.empty:\n",
        "                    pedidos = otimizar_pedidos(p, forecast, lead_time_max)\n",
        "                    pedidos_agrupados.append(pedidos)\n",
        "    return pd.concat(pedidos_agrupados) if pedidos_agrupados else pd.DataFrame()\n",
        "\n",
        "# Processar produtos\n",
        "forecast_dict = {}\n",
        "for produto in df['PRODUTO'].unique():\n",
        "    forecast = prever_demanda_hibrida(produto, df_combined)\n",
        "    forecast_dict[produto] = forecast\n",
        "\n",
        "# Gerar pedidos agrupados\n",
        "df_pedidos = agrupar_pedidos(df['PRODUTO'].unique(), lead_times, forecast_dict)\n",
        "\n",
        "# Exibir e salvar\n",
        "if not df_pedidos.empty:\n",
        "    print(\"Resumo das Previsões e Pedidos para 2025:\")\n",
        "    for produto in df_pedidos['Produto'].unique():\n",
        "        pedidos_produto = df_pedidos[df_pedidos['Produto'] == produto]\n",
        "        print(f\"\\nProduto: {produto}\")\n",
        "        print(pedidos_produto[['Data_Pedido', 'Data_Demanda', 'Quantidade_Pedido']].head())\n",
        "\n",
        "    output_path = os.path.join(os.getcwd(), 'pedidos_2025_avancado.csv')\n",
        "    try:\n",
        "        df_pedidos.to_csv(output_path, index=False)\n",
        "        print(f\"\\nArquivo '{output_path}' gerado com sucesso.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao salvar o arquivo: {e}\")\n",
        "else:\n",
        "    print(\"Nenhum pedido gerado devido a dados insuficientes.\")"
      ]
    }
  ]
}